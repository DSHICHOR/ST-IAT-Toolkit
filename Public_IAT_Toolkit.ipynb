{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4caa6db8-eefe-41e9-84f6-f872c00224b4",
   "metadata": {},
   "source": [
    "# ST-IAT (Single Target Implict Association Test) Analysis Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da1069-c658-4e67-b0c8-85d0111b2246",
   "metadata": {},
   "source": [
    "This toolkit is intended to be used with a Single-Target IAT built on Gorilla software with participant recruitment from Prolific, but is applicable to similar experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99175a4f-74cc-4a8d-8bd5-7dc4f7ca7237",
   "metadata": {},
   "source": [
    "Some of the tools built here are specific to the input files and data strucutre from my experiement. The D score calculation and means comparison algorithems are the most useful for general ST-IAT analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b4086-98d0-4c0b-8f31-e9cec0a6d798",
   "metadata": {},
   "source": [
    "Some variable names will need to be adjusted depending on the input and your specific experiement design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cba577-0110-4e7c-88b6-a9a457ad33f4",
   "metadata": {},
   "source": [
    "## Experiment Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8da69-599b-4f0b-ba88-154b8fc5ae36",
   "metadata": {},
   "source": [
    "This toolkit was built to analyse an ST-IAT in a 5 block configuration as follows: \n",
    "1. Training - Two concepts\n",
    "2. Training - Congruent\n",
    "3. Test - Congruent\n",
    "4. Training - incongruent\n",
    "5. Test - incongruent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3414ee7-0c1b-4815-b138-aa1f432320d5",
   "metadata": {},
   "source": [
    "Participants were shown either the congruent condition first or incongruent condition first, randomaly asigned and split evenly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651006d3-832f-4efc-b6f9-d8562e23e497",
   "metadata": {},
   "source": [
    "# Split results into individual CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ed891-5a0d-40d7-884c-6548a4dd866d",
   "metadata": {},
   "source": [
    "Gorilla exports the experiement data for all participants in each condition as one CSV. I this steps splits the file into individual participant CSVs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91183e55-a30a-48e1-b58d-c70ac6f3e561",
   "metadata": {},
   "source": [
    "## Runs on output file from Gorilla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753719e7-c641-4fac-8bb0-4c252bcee8ed",
   "metadata": {},
   "source": [
    "## Run on both output files - Congruent & Incongruent - to generate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f3c10-0a3c-478d-b1b0-19c0a7a7865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "file_path = \"yourfile.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the header\n",
    "header = data.iloc[0:1]\n",
    "\n",
    "# Extract all unique Participant Private IDs\n",
    "unique_participants = data['Participant Private ID'].unique()\n",
    "\n",
    "# Loop through each unique participant ID and create a separate CSV file\n",
    "for participant in unique_participants:\n",
    "    # Subset data for the current participant\n",
    "    participant_data = data[data['Participant Private ID'] == participant]\n",
    "    \n",
    "    # Prepend the header to the participant's data\n",
    "    participant_data_with_header = pd.concat([header, participant_data])\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file_path = f\"Participant_{participant}.csv\"\n",
    "    \n",
    "    # Write the participant's data to a CSV file\n",
    "    participant_data_with_header.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(f\"Written file for Participant ID: {participant}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ed7b49-c40a-4ce6-9876-44c47ab7b7dc",
   "metadata": {},
   "source": [
    "# Calculate D Score & Means for Each Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e118f2-2791-42e9-9616-ec9a02667299",
   "metadata": {},
   "source": [
    "This is based on the improved IAT D score protocol (Greenwald et al., 2003) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ea885-8c86-4258-9f98-d5d12d3bee90",
   "metadata": {},
   "source": [
    "## Run on folder with all individual participant files - creates unified CSV with D score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69926e5-3dda-42d2-bc10-b9613ebd3820",
   "metadata": {},
   "source": [
    "## Creates 2 files: D score & Block mean calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdce29f-4772-499b-adfc-0bc64f7f46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "def detect_encoding(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        return result['encoding']\n",
    "\n",
    "def process_file(file):\n",
    "    if not file.endswith('.csv'):\n",
    "        return None, \"File is not a CSV\"\n",
    "\n",
    "    # Detect file encoding\n",
    "    encoding = detect_encoding(file)\n",
    "\n",
    "    # Process .CSV file with detected encoding\n",
    "    df = pd.read_csv(file, header=0, skiprows=[1], encoding=encoding)\n",
    "\n",
    "    # Check if 'Reaction Time' exists in the columns\n",
    "    if 'Reaction Time' not in df.columns:\n",
    "        return None, \"'Reaction Time' column not found\"\n",
    "\n",
    "    # 1. Delete all trials with RT greater than 10,000 msec\n",
    "    df = df[df['Reaction Time'] < 10000]\n",
    "\n",
    "    # 2. Delete subjects for whom more than 10% of trials have RT less than 300 msec\n",
    "    if df[df['Reaction Time'] < 300].shape[0] / df.shape[0] > 0.1:\n",
    "        return None, \"Excluded due to more than 10% of trials with RT < 300 ms\"\n",
    "\n",
    "    # 3. Delete all \"incorrect = 1\" results\n",
    "    df = df[df['Incorrect'] != 1]\n",
    "\n",
    "    # Compute SD & Mean for each block\n",
    "    results = {}\n",
    "    mean_results = {}\n",
    "    for condition in df['metaVirtual'].unique():\n",
    "        condition_data = df[df['metaVirtual'] == condition]['Reaction Time']\n",
    "\n",
    "        # Check for NaN or non-numeric values\n",
    "        if condition_data.isnull().values.any() or not pd.api.types.is_numeric_dtype(condition_data):\n",
    "            return None, f\"Non-numeric or NaN values found in condition: {condition}\"\n",
    "\n",
    "        # Check if we have at least two data points to calculate standard deviation\n",
    "        if condition_data.size < 2:\n",
    "            return None, f\"Not enough data points to compute standard deviation for condition: {condition}\"\n",
    "\n",
    "        results[\"stdev_\" + condition] = condition_data.std()\n",
    "        results[\"mean_\" + condition] = condition_data.mean()\n",
    "        \n",
    "        # Save means to mean_results for CSV\n",
    "        mean_results[\"mean_\" + condition] = condition_data.mean()\n",
    "        \n",
    "    # Ensure all necessary conditions were found\n",
    "    required_conditions = [\"congruent_1\", \"congruent_2\", \"incongruent_1\", \"incongruent_2\"]\n",
    "    for condition in required_conditions:\n",
    "        if f\"mean_{condition}\" not in results or f\"stdev_{condition}\" not in results:\n",
    "            return None, f\"Missing mean or standard deviation for condition: {condition}\"\n",
    "\n",
    "    # 4a. Compute inclusive sd for combined conditions\n",
    "    sd24_data = pd.concat([df[df['metaVirtual'] == \"congruent_1\"]['Reaction Time'], \n",
    "                           df[df['metaVirtual'] == \"incongruent_1\"]['Reaction Time']])\n",
    "    results[\"sd24\"] = sd24_data.std()\n",
    "\n",
    "    sd35_data = pd.concat([df[df['metaVirtual'] == \"congruent_2\"]['Reaction Time'], \n",
    "                           df[df['metaVirtual'] == \"incongruent_2\"]['Reaction Time']])\n",
    "    results[\"sd35\"] = sd35_data.std()\n",
    "\n",
    "    # 5. Compute two mean differences\n",
    "    results[\"mean_diff_1\"] = results[\"mean_incongruent_1\"] - results[\"mean_congruent_1\"]\n",
    "    results[\"mean_diff_2\"] = results[\"mean_incongruent_2\"] - results[\"mean_congruent_2\"]\n",
    "\n",
    "    # 6. Divide each difference score by its associated \"inclusive\" standard deviation\n",
    "    results[\"ratio_1\"] = results[\"mean_diff_1\"] / results[\"sd24\"]\n",
    "    results[\"ratio_2\"] = results[\"mean_diff_2\"] / results[\"sd35\"]\n",
    "\n",
    "    # 7. D = the equal weight average of the two resulting ratios\n",
    "    output = {}\n",
    "    output[\"D\"] = (results[\"ratio_1\"] + results[\"ratio_2\"]) / 2\n",
    "    output[\"Participant Private ID\"] = int(df[\"Participant Private ID\"].unique()[0])\n",
    "    output[\"Spreadsheet\"] = df[\"Spreadsheet\"].unique()[0]\n",
    "\n",
    "    # Include the mean results in the output\n",
    "    output.update(mean_results)\n",
    "    \n",
    "    return output, None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    results = []\n",
    "    data_path = '/directory_path' #enter directory path\n",
    "    for file in os.listdir(data_path):\n",
    "        # full path to the file\n",
    "        full_file_path = os.path.join(data_path, file)\n",
    "        result, error_message = process_file(full_file_path)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "        else:\n",
    "            print(f\"File {full_file_path} excluded: {error_message}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('results_mean_calc.csv', index=False)\n",
    "\n",
    "    # Separate CSV for mean values #This file may be redundant\n",
    "    mean_columns = [col for col in results_df.columns if col.startswith('mean_')]\n",
    "    mean_df = results_df[[\"Participant Private ID\", \"Spreadsheet\"] + mean_columns]\n",
    "    mean_df.to_csv('mean_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff26b6-ad20-41f0-b3de-de5509079cbb",
   "metadata": {},
   "source": [
    "# D Score Significance & Conditions Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b5bc3-1d1a-4da5-85b7-117af02374e2",
   "metadata": {},
   "source": [
    "Calculates D score for each condition participant and checks for significant difference. I have not seen this used in literature but wanted to check on my own data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81d315-b4a2-462e-99b9-7d49e2a95edd",
   "metadata": {},
   "source": [
    "## Run on D score result file - results_mean_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1efd80-4260-4c35-9b3a-e2e8b7ca1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = \"results_mean_calc.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the D scores and conditions\n",
    "d_scores = data['D']\n",
    "conditions = data['Spreadsheet']\n",
    "\n",
    "# Count the number of D scores\n",
    "num_d_scores = len(d_scores)\n",
    "print(f\"Number of D scores: {num_d_scores}\")\n",
    "\n",
    "# Calculate the overall mean and standard deviation of D scores\n",
    "mean_d = np.mean(d_scores)\n",
    "std_d = np.std(d_scores, ddof=1)\n",
    "print(f\"Overall mean D score: {mean_d}\")\n",
    "print(f\"Overall standard deviation of D scores: {std_d}\")\n",
    "\n",
    "# Perform a one-sample t-test against the population mean of 0\n",
    "t_stat, p_value = stats.ttest_1samp(d_scores, 0)\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. The mean D score is significantly different from zero.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference from zero.\")\n",
    "\n",
    "# Calculate the Mean, SD and count for each condition\n",
    "conditions = data['Spreadsheet'].unique()\n",
    "for condition in conditions:\n",
    "    condition_scores = data[data['Spreadsheet'] == condition]['D']\n",
    "    mean_condition = np.mean(condition_scores)\n",
    "    std_condition = np.std(condition_scores, ddof=1)\n",
    "    count_condition = len(condition_scores)\n",
    "    print(f\"\\nCondition: {condition}\")\n",
    "    print(f\"Number of D scores: {count_condition}\")\n",
    "    print(f\"Mean D score: {mean_condition}\")\n",
    "    print(f\"Standard Deviation: {std_condition}\")\n",
    "\n",
    "# Perform independent samples t-test between the two conditions\n",
    "congruent_scores = data[data['Spreadsheet'] == 'Congruent_First']['D']\n",
    "incongruent_scores = data[data['Spreadsheet'] == 'Incongruent_First']['D']\n",
    "\n",
    "# Number of D scores in each condition\n",
    "num_congruent = len(congruent_scores)\n",
    "num_incongruent = len(incongruent_scores)\n",
    "\n",
    "print(f\"\\nNumber of D scores in 'Congruent_First': {num_congruent}\")\n",
    "print(f\"Number of D scores in 'Incongruent_First': {num_incongruent}\")\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic, p_value = stats.ttest_ind(congruent_scores, incongruent_scores)\n",
    "\n",
    "# Print the results of the t-test\n",
    "print(\"\\nIndependent Samples t-Test:\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Interpret the result\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. The difference between the means of the two conditions is significant.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The difference between the means of the two conditions is not significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b9167-b1fc-4cb7-8a90-2720ac64a877",
   "metadata": {},
   "source": [
    "# Compare condition means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf32c16-3a3d-4877-a67a-8c9a041d5a72",
   "metadata": {},
   "source": [
    "## Runs on mean_calc file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161e92f-6787-4859-99fe-93964d3c4ffc",
   "metadata": {},
   "source": [
    "This steps compares the mean RT of each condition block for all participants. Ideally you want to see a significant difference between the congruent and incongruent conditions regardless of the order they were presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3920f66-e887-411a-8156-26ecec33c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "def main():\n",
    "    # Load the CSV file with mean results\n",
    "    df = pd.read_csv('results_mean_calc.csv')\n",
    "    \n",
    "    # Calculate the combined mean for congruent conditions\n",
    "    df['mean_congruent_combined'] = df[['mean_congruent_1', 'mean_congruent_2']].mean(axis=1)\n",
    "    \n",
    "    # Calculate the combined mean for incongruent conditions\n",
    "    df['mean_incongruent_combined'] = df[['mean_incongruent_1', 'mean_incongruent_2']].mean(axis=1)\n",
    "\n",
    "    # Calculate the aggregated mean across all participants for congruent conditions\n",
    "    total_mean_congruent_combined = df['mean_congruent_combined'].mean()\n",
    "    \n",
    "    # Calculate the aggregated mean across all participants for incongruent conditions\n",
    "    total_mean_incongruent_combined = df['mean_incongruent_combined'].mean()\n",
    "    \n",
    "    # Calculate standard deviations\n",
    "    sd_congruent_combined = df['mean_congruent_combined'].std()\n",
    "    sd_incongruent_combined = df['mean_incongruent_combined'].std()\n",
    "\n",
    "    # Perform paired sample t-test\n",
    "    t_statistic, p_value = ttest_rel(df['mean_congruent_combined'], df['mean_incongruent_combined'])\n",
    "\n",
    "    # Output the results\n",
    "    print(\"Combined Mean for Congruent Conditions (mean congruent_1 & mean_congruent_2):\", total_mean_congruent_combined)\n",
    "    print(\"Combined Mean for Incongruent Conditions (mean incongruent_1 & mean_incongruent_2):\", total_mean_incongruent_combined)\n",
    "    print(\"Standard Deviation for Congruent Conditions:\", sd_congruent_combined)\n",
    "    print(\"Standard Deviation for Incongruent Conditions:\", sd_incongruent_combined)\n",
    "    \n",
    "    # Report the t-test results\n",
    "    print(\"Paired Sample t-test:\")\n",
    "    print(\"t-statistic:\", t_statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "    \n",
    "    # Determine significance\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(\"The difference between the combined means is statistically significant (p < 0.05).\")\n",
    "    else:\n",
    "        print(\"The difference between the combined means is not statistically significant (p >= 0.05).\")\n",
    "    \n",
    "    # Optionally, write the combined means and additional statistics to a new CSV file for further usage\n",
    "    combined_means = {\n",
    "        'mean_congruent_combined': [total_mean_congruent_combined],\n",
    "        'mean_incongruent_combined': [total_mean_incongruent_combined],\n",
    "        'sd_congruent_combined': [sd_congruent_combined],\n",
    "        'sd_incongruent_combined': [sd_incongruent_combined],\n",
    "        't_statistic': [t_statistic],\n",
    "        'p_value': [p_value],\n",
    "        'significance': ['Significant' if p_value < alpha else 'Not Significant']\n",
    "    }\n",
    "    combined_means_df = pd.DataFrame(combined_means)\n",
    "    combined_means_df.to_csv('combined_means_comparison.csv', index=False)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d29b7-fb95-4e58-9e04-a4cc1f79d331",
   "metadata": {},
   "source": [
    "# Compare demographics & survey questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e3a0c-0ed7-40f7-b554-6d9d69f12cfe",
   "metadata": {},
   "source": [
    "## Run on participant demographic file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42712310-f3e7-4f67-b554-f97f399f0c7d",
   "metadata": {},
   "source": [
    "I included a demographic questioneer in Gorilla following the experimental task, as well as a 3 question survey. This step generates some demographic statistics and creates a new file with participants responses to the survey. Feel free to modify this step or ignore it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf492c1-fdfb-47a2-aba3-12641bf45827",
   "metadata": {},
   "source": [
    "## Gives demographic statistics & creates file with survey responses for each participant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d86597-680a-44fe-b5c0-e72b0667fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the input CSV file\n",
    "input_file_path = \"/Users/Michael/Library/Mobile Documents/com~apple~CloudDocs/Documents/School/PHD/Extended Essay/Implicit Association Test/Data/IAT Data/UK/Full 100/data_exp_176416-v11 (5)/data_exp_176416-v11_questionnaire-7y5d.csv\"\n",
    "# Path to the output CSV file\n",
    "output_file_path = \"/Users/Michael/IAT/UKRun/UK_Demographic_Final100.CSV\"\n",
    "\n",
    "# Read the input CSV file into a DataFrame\n",
    "data = pd.read_csv(input_file_path)\n",
    "\n",
    "# Prepare a dictionary to collect the necessary information for each participant\n",
    "participant_info = {}\n",
    "\n",
    "# Fill the dictionary with participant information\n",
    "for index, row in data.iterrows():\n",
    "    participant_id = row['Participant Private ID']\n",
    "    \n",
    "    if participant_id not in participant_info:\n",
    "        participant_info[participant_id] = {\n",
    "            'Participant ID': participant_id,\n",
    "            'Participant Age': None,\n",
    "            'Participant Gender': None,\n",
    "            'response-familiar': None,\n",
    "            'response-purchase': None,\n",
    "            'response-use': None,\n",
    "            'cronbach_alpha': None  # Initialize Cronbach's alpha column\n",
    "        }\n",
    "    \n",
    "    question_key = row['Question Key']\n",
    "    response = row['Response']\n",
    "    \n",
    "    if question_key == 'age':\n",
    "        participant_info[participant_id]['Participant Age'] = response\n",
    "    elif question_key == 'gender':\n",
    "        participant_info[participant_id]['Participant Gender'] = response\n",
    "    elif question_key == 'response-familiar':\n",
    "        participant_info[participant_id]['response-familiar'] = response\n",
    "    elif question_key == 'response-purchase':\n",
    "        participant_info[participant_id]['response-purchase'] = response\n",
    "    elif question_key == 'response-use':\n",
    "        participant_info[participant_id]['response-use'] = response\n",
    "\n",
    "# Calculate Cronbach's alpha for each participant\n",
    "for participant_id, info in participant_info.items():\n",
    "    # Extract responses for the three questions\n",
    "    responses = {\n",
    "        'response-familiar': info['response-familiar'],\n",
    "        'response-purchase': info['response-purchase'],\n",
    "        'response-use': info['response-use']\n",
    "    }\n",
    "    \n",
    "    # Check if any response is None (missing)\n",
    "    if None not in responses.values():\n",
    "        # Convert to DataFrame\n",
    "        response_df = pd.DataFrame([responses], dtype=float)\n",
    "        # Calculate Cronbach's alpha\n",
    "        alpha = cronbach_alpha(response_df)\n",
    "        participant_info[participant_id]['cronbach_alpha'] = alpha\n",
    "\n",
    "# Create a DataFrame from the participant_info dictionary\n",
    "output_data = pd.DataFrame.from_dict(participant_info, orient='index')\n",
    "\n",
    "# Convert 'Participant Age' to numeric (it will convert NaN for non-numeric entries)\n",
    "output_data['Participant Age'] = pd.to_numeric(output_data['Participant Age'], errors='coerce')\n",
    "\n",
    "# Calculate mean age and standard deviation\n",
    "mean_age = output_data['Participant Age'].mean()\n",
    "std_age = output_data['Participant Age'].std()\n",
    "\n",
    "# Count number of participants by gender\n",
    "gender_counts = output_data['Participant Gender'].value_counts()\n",
    "\n",
    "# Write the output DataFrame to a new CSV file\n",
    "output_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Data extraction complete. New CSV file created.\")\n",
    "print(f\"Mean age: {mean_age}\")\n",
    "print(f\"Age standard deviation: {std_age}\")\n",
    "print(\"Gender counts:\")\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456c84f-c102-435f-b5fa-7400ad11890f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
